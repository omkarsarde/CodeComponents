{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "data = pd.read_csv('data.csv')\n",
    "extra_data = pd.read_csv('extra_data.csv')\n",
    "\n",
    "# Combine datasets\n",
    "combined_data = pd.concat([data, extra_data])  # Redundant operation\n",
    "\n",
    "print(\"Data Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Cleaning\n",
    "# Remove duplicates and fill missing values\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Extra Cleaning (redundant)\n",
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"Data cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Engineering\n",
    "data['feature_1'] = data['col1'] * data['col2']\n",
    "data['feature_2'] = data['feature_1'] + data['col3']  # Intermediate calculation\n",
    "\n",
    "# Add new feature\n",
    "data['extra_feature'] = data['feature_2'] - data['col4']\n",
    "\n",
    "print(\"Features engineered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "X = data[['feature_1', 'feature_2', 'extra_feature']]\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split
