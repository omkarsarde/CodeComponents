{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Customer Churn Prediction\n",
       "## Data Analysis, Feature Engineering, Model Development, and Model Saving"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Step 1: Load Libraries and Dataset\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "from sklearn.model_selection import train_test_split, GridSearchCV\n",
       "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
       "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
       "import pickle\n",
       "\n",
       "# Load dataset\n",
       "data = pd.read_csv('data.csv')\n",
       "data.head()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Step 2: Feature Engineering\n",
       "data['income_per_year'] = data['annual_income'] / (data['years_with_company'] + 1)\n",
       "data['purchases_per_year'] = data['total_purchases'] / (data['years_with_company'] + 1)\n",
       "data['spend_per_purchase'] = data['total_spent'] / (data['total_purchases'] + 1)\n",
       "\n",
       "# Encode gender\n",
       "data['gender'] = data['gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
       "\n",
       "# Polynomial Features\n",
       "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
       "poly_features = poly.fit_transform(data[['income_per_year', 'purchases_per_year', 'spend_per_purchase']])\n",
       "poly_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out())\n",
       "data = pd.concat([data, poly_df], axis=1)\n",
       "\n",
       "data.drop(columns=['customer_id'], inplace=True)\n",
       "data.head()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Step 3: Train-Test Split\n",
       "X = data.drop(columns=['is_active'])\n",
       "y = data['is_active']\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "# Scaling\n",
       "scaler = StandardScaler()\n",
       "X_train_scaled = scaler.fit_transform(X_train)\n",
       "X_test_scaled = scaler.transform(X_test)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Step 4: Model Training with Hyperparameter Tuning\n",
       "# Logistic Regression\n",
       "lr = LogisticRegression()\n",
       "lr.fit(X_train_scaled, y_train)\n",
       "lr_preds = lr.predict(X_test_scaled)\n",
       "\n",
       "# Random Forest\n",
       "rf = RandomForestClassifier(random_state=42)\n",
       "rf_params = {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10]}\n",
       "rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='accuracy')\n",
       "rf_grid.fit(X_train, y_train)\n",
       "\n",
       "# Gradient Boosting\n",
       "gb = GradientBoostingClassifier(random_state=42)\n",
       "gb_params = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
       "gb_grid = GridSearchCV(gb, gb_params, cv=3, scoring='accuracy')\n",
       "gb_grid.fit(X_train, y_train)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Step 5: Model Evaluation\n",
       "models = {'Logistic Regression': lr, 'Random Forest': rf_grid.best_estimator_, 'Gradient Boosting': gb_grid.best_estimator_}\n",
       "for name, model in models.items():\n",
       "    preds = model.predict(X_test_scaled)\n",
       "    print(f\"Model: {name}\")\n",
       "    print(f\"Accuracy: {accuracy_score(y_test, preds)}\")\n",
       "    print(f\"ROC AUC: {roc_auc_score(y_test, preds)}\")\n",
       "    print(classification_report(y_test, preds))\n",
       "    print(\"-\" * 50)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Step 6: Save the Best Model\n",
       "best_model = gb_grid.best_estimator_  # Assuming Gradient Boosting performed best\n",
       "with open('best_model.pkl', 'wb') as file:\n",
       "    pickle.dump(best_model, file)\n",
       "print(\"Best model saved as best_model.pkl\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
   